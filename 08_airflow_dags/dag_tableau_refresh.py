"""
Airflow DAG: Tableau ë°ì´í„° ê°±ì‹  íŒŒì´í”„ë¼ì¸
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ì¼ê°„ ì§€í‘œ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ í›„ Tableauìš© CSVë¥¼ ê°±ì‹ í•˜ê³ 
Tableau Server/Onlineì˜ Extractë¥¼ ë¦¬í”„ë ˆì‹œí•©ë‹ˆë‹¤.
(Tableau Public ì‚¬ìš© ì‹œì—ëŠ” ìˆ˜ë™ ì—…ë¡œë“œê°€ í•„ìš”í•©ë‹ˆë‹¤)
"""

from datetime import datetime, timedelta

from airflow import DAG
from airflow.operators.bash import BashOperator
from airflow.operators.python import PythonOperator
from airflow.sensors.external_task import ExternalTaskSensor

default_args = {
    "owner": "dataops",
    "depends_on_past": False,
    "retries": 1,
    "retry_delay": timedelta(minutes=5),
}

dag = DAG(
    dag_id="quickpay_tableau_refresh",
    default_args=default_args,
    description="Tableau ë°ì´í„° ê°±ì‹  (daily_metrics DAG ì™„ë£Œ í›„ ì‹¤í–‰)",
    schedule_interval="0 22 * * *",  # UTC 22:00 = KST 07:00 (daily_metrics 1ì‹œê°„ í›„)
    start_date=datetime(2025, 11, 15),
    catchup=False,
    tags=["quickpay", "tableau", "visualization"],
    max_active_runs=1,
)

# â”â”â” Task 1: ì¼ê°„ ì§€í‘œ DAG ì™„ë£Œ ëŒ€ê¸° â”â”â”
wait_for_daily_metrics = ExternalTaskSensor(
    task_id="wait_for_daily_metrics",
    external_dag_id="quickpay_daily_metrics",
    external_task_id="notify_success",
    execution_delta=timedelta(hours=1),  # 1ì‹œê°„ ì „ DAG
    timeout=3600,  # ìµœëŒ€ 1ì‹œê°„ ëŒ€ê¸°
    poke_interval=60,  # 1ë¶„ë§ˆë‹¤ í™•ì¸
    mode="reschedule",
    dag=dag,
)

# â”â”â” Task 2: Tableau CSV ë‚´ë³´ë‚´ê¸° â”â”â”
export_csv = BashOperator(
    task_id="export_tableau_csv",
    bash_command="""
        cd /opt/airflow/dags/fintech-dataops-portfolio
        python 06_tableau_dashboard/export_tableau_data.py 2>&1
        
        # íŒŒì¼ í¬ê¸° ë° í–‰ ìˆ˜ ê²€ì¦
        for f in 06_tableau_dashboard/exports/*.csv; do
            rows=$(wc -l < "$f")
            size=$(du -h "$f" | cut -f1)
            echo "ğŸ“ $(basename $f): ${rows} rows, ${size}"
            
            if [ "$rows" -lt 2 ]; then
                echo "âŒ ERROR: $f has no data rows!"
                exit 1
            fi
        done
        
        echo "âœ… All Tableau CSV files exported successfully"
    """,
    dag=dag,
)

# â”â”â” Task 3: ë°ì´í„° ê²€ì¦ (Tableau ê³µê¸‰ ë°ì´í„° ì •í•©ì„±) â”â”â”
def _validate_tableau_data(**kwargs):
    """Tableau CSVì˜ ê¸°ë³¸ ì •í•©ì„± ê²€ì¦"""
    import pandas as pd
    from pathlib import Path
    
    export_dir = Path("/opt/airflow/dags/fintech-dataops-portfolio/06_tableau_dashboard/exports")
    
    # daily_kpi.csv ê²€ì¦
    daily = pd.read_csv(export_dir / "daily_kpi.csv")
    assert len(daily) > 0, "daily_kpi.csv is empty"
    assert daily["dau"].min() > 0, "DAU has zero or negative values"
    assert daily["gmv"].min() >= 0, "GMV has negative values"
    print(f"âœ… daily_kpi.csv: {len(daily)} rows, DAU range [{daily['dau'].min()}, {daily['dau'].max()}]")
    
    # retention_cohort.csv ê²€ì¦
    retention = pd.read_csv(export_dir / "retention_cohort.csv")
    assert len(retention) > 0, "retention_cohort.csv is empty"
    assert retention["retention_rate"].max() <= 100, "Retention rate exceeds 100%"
    print(f"âœ… retention_cohort.csv: {len(retention)} rows")
    
    # funnel_data.csv ê²€ì¦
    funnel = pd.read_csv(export_dir / "funnel_data.csv")
    assert len(funnel) == 6, f"funnel should have 6 steps, got {len(funnel)}"
    assert funnel.iloc[0]["pct_from_start"] == 100.0, "First funnel step should be 100%"
    print(f"âœ… funnel_data.csv: {len(funnel)} steps")
    
    # transaction_summary.csv ê²€ì¦
    txn = pd.read_csv(export_dir / "transaction_summary.csv")
    assert len(txn) > 0, "transaction_summary.csv is empty"
    assert txn["total_amount"].min() >= 0, "Negative total_amount found"
    print(f"âœ… transaction_summary.csv: {len(txn)} rows")
    
    print("\nâœ… All Tableau data validation passed!")


validate_data = PythonOperator(
    task_id="validate_tableau_data",
    python_callable=_validate_tableau_data,
    dag=dag,
)

# â”â”â” Task 4: ì™„ë£Œ ì•Œë¦¼ â”â”â”
def _notify_tableau_refresh(**kwargs):
    """Tableau ë°ì´í„° ê°±ì‹  ì™„ë£Œ ì•Œë¦¼"""
    execution_date = kwargs.get("ds", "unknown")
    print(f"ğŸ“Š Tableau data refresh completed for {execution_date}")
    print("ğŸ“Œ Tableau Public ì‚¬ìš© ì‹œ: ìˆ˜ë™ìœ¼ë¡œ ë°ì´í„° ì†ŒìŠ¤ë¥¼ ì—…ë°ì´íŠ¸í•˜ì„¸ìš”.")
    print("ğŸ“Œ Tableau Server ì‚¬ìš© ì‹œ: Hyper íŒŒì¼ì´ ìë™ ê°±ì‹ ë˜ì—ˆìŠµë‹ˆë‹¤.")


notify_refresh = PythonOperator(
    task_id="notify_tableau_refresh",
    python_callable=_notify_tableau_refresh,
    dag=dag,
)

# â”â”â” DAG ì˜ì¡´ì„± â”â”â”
wait_for_daily_metrics >> export_csv >> validate_data >> notify_refresh
